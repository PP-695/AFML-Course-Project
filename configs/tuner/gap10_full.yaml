# Full Gap 10 Configuration Example
# This config demonstrates all Gap 10 features enabled for CIFAR100-LT (IR=100)
# Use this as a reference for configuring your experiments

# Base FLoRA configuration
use_flora: True
use_meta: True
use_class_aware: True

flora:
  arch:
    modules: ["q", "k", "v", "out", "mlp1", "mlp2"]
    layers: [0,1,2,3,4,5,6,7,8,9,10,11]
    alpha: 1.0
    rank: 8  # Base rank

# Class-aware settings
class_aware:
  num_class_groups: 3  # head, medium, tail
  class_grouping_strategy: "threshold"  # or "frequency"

  # Thresholds for grouping (used with threshold strategy)
  head_threshold: 100  # Classes with >= 100 samples
  tail_threshold: 20   # Classes with < 20 samples

  # Initial rank factors per group
  head_rank_factor: 0.5   # Head classes use lower rank (less adaptation needed)
  tail_rank_factor: 2.0   # Tail classes use higher rank (more adaptation needed)

  # Initial alpha factors per group
  head_alpha_factor: 0.5  # Head classes use lower alpha
  tail_alpha_factor: 2.0  # Tail classes use higher alpha

# ============================================================================
# Gap 10 Feature Set
# ============================================================================

# Gap 10: COCL-style loss components
cocl:
  # Enable individual loss components
  use_ocl: True  # Outlier Class Learning with explicit OOD class
  use_tail_proto: True  # Tail prototype learning for OOD separation
  use_head_debias: True  # Debiased head loss for better calibration
  
  # Loss weights (balance with main classification loss)
  lambda_ocl: 0.5  # Weight for OCL loss (0.3-0.7 recommended)
  lambda_tail_proto: 0.3  # Weight for tail prototype loss (0.2-0.5 recommended)
  lambda_head_debias: 0.1  # Weight for head debiasing loss (0.05-0.2 recommended)
  
  # OCL parameters
  ocl_weight: 1.0  # Relative weight for OOD samples in OCL
  
  # Tail prototype parameters
  tail_proto_temperature: 0.07  # Temperature for contrastive learning (0.05-0.1)
  tail_proto_margin: 0.1  # Margin for tail-OOD separation (0.0-0.2)
  
  # Head debiasing parameters
  head_debias_penalty: 0.1  # Penalty weight for head over-confidence (0.05-0.2)
  
  # Calibration parameters (for inference/evaluation)
  use_logit_calibration: True  # Enable calibrated logit adjustment at test time
  tau_calibrate: 1.0  # Temperature for logit calibration (0=no adjustment, 1=full)

# Gap 10: OOD dataset configuration for training
ood:
  use_ood: True  # Enable auxiliary OOD data during training
  
  # OOD dataset selection
  # Options: "tinyimages", "places365", "lsun", "textures", "svhn", "gaussian", "uniform"
  # Or provide custom path
  ood_dataset: "tinyimages"
  ood_data_path: "./data"  # Root path for OOD datasets
  
  # OOD sampling parameters
  ood_batch_size: 32  # Batch size for OOD data (match or smaller than main batch)
  ood_num_samples: 10000  # Number of OOD samples to use (0 = use all)

# Gap 10: EAT-style tail augmentation
tail_augmentation:
  use_tail_cutmix: True  # Enable CutMix augmentation for tail classes
  
  # CutMix parameters
  tail_cutmix_alpha: 0.9999  # Beta distribution parameter (high = more tail preserved)
                             # 0.9999 means ~99% tail, ~1% background
  tail_cutmix_prob: 0.5  # Probability of applying CutMix to tail samples
  
  # Advanced options
  use_ood_paste: True  # Paste tail patches into OOD images (vs. head images)
  apply_to_medium: False  # Also apply augmentation to medium classes (experimental)

# Gap 10: OOD detection evaluation
ood_eval:
  enable: True  # Enable OOD detection metrics during evaluation
  
  # OOD test datasets (evaluated against in-distribution test set)
  # Options: "textures", "svhn", "lsun", "places365", "tinyimages", "gaussian", "uniform"
  ood_test_datasets: 
    - "textures"  # Describable Textures Dataset
    - "svhn"      # Street View House Numbers
    - "lsun"      # Large-scale Scene Understanding
  
  # OOD scoring method
  # Options: "msp" (max-softmax), "energy", "odin"
  ood_metric: "msp"  # MSP is fastest; Energy often better; ODIN requires gradient
  
  # Metrics to compute
  compute_auroc: True   # Area Under ROC Curve
  compute_aupr: True    # Area Under Precision-Recall Curve
  compute_fpr95: True   # False Positive Rate at 95% TPR

# Gap 10: Advanced visualizations
visualization:
  enable: True  # Enable advanced visualizations during/after training
  
  # What to save
  save_confmat: True  # Save confusion matrix heatmap
  save_per_class_acc: True  # Save per-class accuracy vs. sample count plot
  save_tsne: False  # Save t-SNE embeddings (computationally expensive, disable for large datasets)
  save_calibration: True  # Save calibration curves / reliability diagrams
  
  # Output directory
  plot_dir: "output/plots"  # Directory for saving plots

# ============================================================================
# Training Configuration (adjust as needed)
# ============================================================================

# Meta-learning parameters
meta_lr: 0.001  # Learning rate for meta-parameters
meta_update_freq: 1  # Update meta-params every N epochs
meta_inner_steps: 5  # Number of inner loop steps
meta_data_ratio: 0.1  # Fraction of data for meta-learning

# Regularization
rank_divergence_penalty: 0.01  # Penalty for rank weight divergence
alpha_smoothness_penalty: 0.005  # Penalty for alpha weight smoothness

# Tail class focus
focus_on_tail: True  # Apply higher weight to tail classes
tail_loss_weight: 2.0  # Weight multiplier for tail class samples

# Meta-learning objective
meta_objective: "balanced_accuracy"  # Options: "balanced_accuracy", "g_mean", "worst_case"
